{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"MLP_NYSE.ipynb","provenance":[],"collapsed_sections":["xx39P4x9NsgG","f8OR4dtsLNzj","66b4kq26N7gW","JEC2Nat-PxAc","gNE_MJpfTCpD","_B17pnkMWBSr"],"authorship_tag":"ABX9TyMEkgvl/eGbAP3nZmT8nRE7"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"DGzn_Vz7gLm0"},"source":["# このノートブックは？\n","* CreateInitialData.ipynbで作成したデータを利用し、特徴量作成、MLPでの学習、予測結果のファイル出力を行う\n","* 全データを対象に学習し、予測結果のうちNASDAQ, NASDAQ, AMEXの全てをこの後に利用"]},{"cell_type":"markdown","metadata":{"id":"xx39P4x9NsgG"},"source":["## Google Driveのマウント"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9mi4pP5OIqj_","executionInfo":{"status":"ok","timestamp":1639453162948,"user_tz":-540,"elapsed":2341,"user":{"displayName":"Keisuke Shoji","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10321049352155053308"}},"outputId":"7af3dc0d-a3b1-4711-9403-886cf95dbe1e"},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","%cd /content/drive/'My Drive'/'PROBSPACE'/'StockPricePrediction'"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/My Drive/PROBSPACE/StockPricePrediction\n"]}]},{"cell_type":"markdown","metadata":{"id":"f8OR4dtsLNzj"},"source":["## ライブラリのインストール、インポート"]},{"cell_type":"code","metadata":{"id":"IK_XvkEHeHh0","executionInfo":{"status":"ok","timestamp":1639453179673,"user_tz":-540,"elapsed":13691,"user":{"displayName":"Keisuke Shoji","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10321049352155053308"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"a514df51-a027-47e7-83da-4b63651854dd"},"source":["import src.install_libraries\n","import category_encoders as ce\n","from src.common_functions import *\n","from src.create_features import *\n","import tensorflow as tf\n","from tensorflow.keras import layers, activations\n","!pip install -q -U tensorflow_addons\n","import tensorflow_addons as tfa\n","from collections import defaultdict"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: category_encoders in /usr/local/lib/python3.7/dist-packages (2.3.0)\n","Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from category_encoders) (0.10.2)\n","Requirement already satisfied: pandas>=0.21.1 in /usr/local/lib/python3.7/dist-packages (from category_encoders) (1.1.5)\n","Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.7/dist-packages (from category_encoders) (0.5.2)\n","Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from category_encoders) (1.4.1)\n","Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from category_encoders) (1.19.5)\n","Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.7/dist-packages (from category_encoders) (1.0.1)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.21.1->category_encoders) (2.8.2)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.21.1->category_encoders) (2018.9)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from patsy>=0.5.1->category_encoders) (1.15.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.0->category_encoders) (3.0.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.0->category_encoders) (1.1.0)\n","Requirement already satisfied: ta in /usr/local/lib/python3.7/dist-packages (0.8.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from ta) (1.19.5)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from ta) (1.1.5)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->ta) (2018.9)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->ta) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->ta) (1.15.0)\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n","  import pandas.util.testing as tm\n"]}]},{"cell_type":"markdown","metadata":{"id":"66b4kq26N7gW"},"source":["## データの読み込み"]},{"cell_type":"code","metadata":{"id":"-1T_7c2Vb1hR"},"source":["price_df2, company_df2, submission_df = read_initial_data()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"A2IPxqg5ENZM"},"source":["# 乱数固定\n","SEED = 42\n","seed_everything(SEED)\n","\n","set_pandas_options()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JEC2Nat-PxAc"},"source":["## 特徴量追加"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":720},"id":"lG1hB0NhPzDs","executionInfo":{"status":"ok","timestamp":1639453215755,"user_tz":-540,"elapsed":22716,"user":{"displayName":"Keisuke Shoji","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10321049352155053308"}},"outputId":"0bf45569-3a03-43b5-d2f6-398d6dbeee36"},"source":["def create_features(df, group_col, val_col1, val_col2, prefix):\n","  res = pd.DataFrame(index=df.index)\n","  group_df = df.groupby(group_col) if group_col else df.copy()\n","\n","  # ラグ特徴量\n","  with Timer(f'{prefix}ラグ特徴量'):\n","    lag_df = create_lags(group_df, val_col1, [1, 2, 3, 4], prefix)\n","    res = res.join(lag_df)\n","\n","  # 単純移動平均、標準偏差\n","  with Timer(f'{prefix}単純移動平均'):\n","    roll_df = create_rolls(group_df, val_col1, [1], [52], prefix)\n","    res = res.join(roll_df)\n","\n","  # # EMA GAP\n","  # with Timer(f'{prefix}EMA_GAP'):\n","  #   ema_df = create_ema_gap(df, group_df, group_col, val_col1, [13, 26], prefix)\n","  #   res = res.join(ema_df)\n","\n","  # # Return\n","  # with Timer(f'{prefix}Return'):\n","  #   return_df = create_return(group_df, val_col2, [13, 26], prefix)\n","  #   res = res.join(return_df)\n","\n","  # # HV\n","  # with Timer(f'{prefix}HV'):\n","  #   hv_df = create_hv(df, group_df, group_col, val_col2, [13, 26], prefix)\n","  #   res = res.join(hv_df)\n","\n","  # Skew\n","  with Timer(f'{prefix}Skew'):\n","    skew_df = create_skew(df, group_df, group_col, val_col2, [13, 26], prefix)\n","    res = res.join(skew_df)\n","\n","  # # Kurt\n","  # with Timer(f'{prefix}Kurt'):\n","  #   kurt_df = create_kurt(group_df, val_col2, [13, 26], prefix)\n","  #   res = res.join(kurt_df)\n","\n","  # # Var\n","  # with Timer(f'{prefix}Var'):\n","  #   var_df = create_var(group_df, val_col1, [13, 26], prefix)\n","  #   res = res.join(var_df)\n","\n","  # # MIN, MAX\n","  # if group_col:\n","  #   with Timer(f'{prefix}MIN, MAX'):\n","  #     min_max_df = create_min_max(group_df, val_col1, [13, 26], prefix)\n","  #     res = res.join(min_max_df)\n","\n","  # # Up, Down\n","  # if group_col:\n","  #   with Timer(f'{prefix}Up, Down'):\n","  #     up_down_df = create_up_down(df, group_col, val_col1, [13, 26], prefix)\n","  #     res = res.join(up_down_df)\n","\n","  # # ATR\n","  # if group_col:\n","  #   with Timer(f'{prefix}ATR'):\n","  #     atr_df = create_atr(group_df, val_col2, prefix)\n","  #     res = res.join(atr_df)\n","\n","  # # RSI\n","  # if group_col:\n","  #   with Timer(f'{prefix}RSI'):\n","  #     rsi_df = create_rsi(group_df, val_col2, prefix)\n","  #     res = res.join(rsi_df)\n","\n","  # # MACD\n","  # if group_col:\n","  #   with Timer(f'{prefix}MACD'):\n","  #     macd_df = create_macd(group_df, val_col2, prefix)\n","  #     res = res.join(macd_df)\n","\n","  # # BB\n","  # if group_col:\n","  #   with Timer(f'{prefix}BB'):\n","  #     bb_df = create_bb(group_df, val_col2, prefix)\n","  #     res = res.join(bb_df)\n","\n","  # # Stochastic Oscillator\n","  # if group_col:\n","  #   with Timer(f'{prefix}Stochastic Oscillator'):\n","  #     stock_df = create_stock(group_df, val_col2, prefix)\n","  #     res = res.join(stock_df)\n","\n","  # # Parabolic Stop and Reverse\n","  # if group_col:\n","  #   with Timer(f'{prefix}Parabolic Stop and Reverse'):\n","  #     parabolic_df = create_parabolic(group_df, val_col2, prefix)\n","  #     res = res.join(parabolic_df)\n","\n","  # # KST Oscillator\n","  # if group_col:\n","  #   with Timer(f'{prefix}KST Oscillator'):\n","  #     kst_df = create_kst(group_df, val_col2, prefix)\n","  #     res = res.join(kst_df)\n","\n","  return res\n","\n","\n","def add_feature(df):\n","  res = df.copy()\n","\n","  # 日付\n","  res['Year'] = res.Date.dt.year\n","  res['Month'] = res.Date.dt.month\n","  res['Day'] = res.Date.dt.day\n","  res['WeekOfYear'] = res.Date.dt.isocalendar().week.astype(int)\n","\n","  # ターゲットエンコーディング\n","  target_columns = ['Sector', 'Industry', 'List1', 'List2']\n","  ms = ce.MEstimateEncoder(cols=target_columns, m=1.0)\n","  ms_df = ms.fit_transform(res[target_columns], res.y_diff_norm)\n","  res['List'] = res.List1\n","  res.loc[:, target_columns] = ms_df.loc[:, target_columns]\n","\n","  # 各種特徴量作成\n","  res = res.join(create_features(res, 'id', 'y_diff_norm', 'y_prev', ''))\n","\n","  # 市場平均価格を求める\n","  prefix = 'Market_'\n","  tmp_market_df = res[['Date']].copy()\n","  tmp_market_df['y'] = np.expm1(res.y)\n","  market_df = tmp_market_df.groupby('Date').mean().apply(np.log1p).reset_index()\n","  market_df['y_prev'] = market_df['y'].transform(lambda x: x.shift(1).fillna(method='bfill'))\n","  market_df['y_diff'] = market_df['y'] - market_df['y_prev']\n","  market_df['y_diff_std'] = market_df['y'].std()\n","  market_df['y_diff_norm'] = market_df['y_diff'] / market_df['y_diff_std']\n","\n","  market_columns = [prefix + c if c != 'Date' else c for c in market_df.columns]\n","  market_df.columns = market_columns\n","\n","  # 市場平均の各種特徴量作成、結合\n","  market_df = market_df.join(create_features(market_df, None, 'Market_y_diff_norm', 'Market_y_prev', prefix))\n","  res = res.merge(market_df, on='Date')\n","  market_columns = market_df.drop('Date', axis=1).columns.values.tolist()\n","\n","  # 各銘柄の特徴量を相対化\n","  # シャープレシオ\n","  # with Timer(f'Sharp Ratio'):\n","  #   group_df1 = res.groupby('id')\n","  #   group_df2 = market_df\n","  #   sharp_df = sharp_ratio(group_df1, group_df2, 'y_prev', [13, 26])\n","  #   res = res.join(sharp_df)\n","\n","  # 対象列の設定\n","  replace_columns = []\n","  # replace_columns += [f'lag_{i}' for i in [1, 2, 3, 4]]\n","  # replace_columns += [f'rmean_{i}_{j}' for i in [1] for j in [52]]\n","  # replace_columns += [f'rstd_{i}_{j}' for i in [1] for j in [52]]\n","  # replace_columns += [f'EMA_GAP_{i}' for i in [13, 26]]\n","  # replace_columns += [f'Return_{i}' for i in [13, 26]]\n","  # replace_columns += [f'HV_{i}' for i in [13, 26]]\n","  # replace_columns += [f'Skew_{i}' for i in [13, 26]]\n","  # replace_columns += [f'Kurt_{i}' for i in [13, 26]]\n","  # replace_columns += [f'Var_{i}' for i in [13, 26]]\n","\n","  # 市場平均価格の特徴量に対する各銘柄の特徴量を作成\n","  replace_columns_market = [prefix + c for c in replace_columns]\n","  feature_from_market = pd.DataFrame()\n","  for c1, c2 in zip(replace_columns, replace_columns_market):\n","    feature_from_market[f'{c1}_from_Market'] = res[c1] - res[c2]\n","  res = res.drop(replace_columns+market_columns, axis=1).join(feature_from_market).join(res[market_columns])\n","\n","  # 不要な特徴量の削除\n","  drop_columns = []\n","  drop_columns += market_columns\n","  res.drop(drop_columns, axis=1, inplace=True, errors='ignore')\n","\n","  # # PCA\n","  # with Timer('PCA'):\n","  #   res = res.join(pca(res, 2))\n","\n","  # # K-Means\n","  # with Timer('K-Means'):\n","  #   res = res.join(k_means(res, 3))\n","\n","  # 欠損値補完\n","  res.IPOyear.fillna(1970, inplace=True)\n","  target_columns = [x for x in res.columns.values.tolist() if any(s in x for s in ['lag', 'rmean', 'rstd'])]\n","  for c in target_columns:\n","    res[c].fillna(method='bfill', inplace=True)\n","\n","  return res\n","\n","\n","price_df3 = add_feature(price_df2)\n","price_df3"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2021-12-14 12:40:57 ラグ特徴量 実行時間: 0.15分\n","2021-12-14 12:41:01 単純移動平均 実行時間: 0.08分\n","2021-12-14 12:41:03 Skew 実行時間: 0.02分\n","2021-12-14 12:41:03 Market_ラグ特徴量 実行時間: 0.00分\n","2021-12-14 12:41:03 Market_単純移動平均 実行時間: 0.00分\n","2021-12-14 12:41:03 Market_Skew 実行時間: 0.00分\n"]},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Date</th>\n","      <th>id</th>\n","      <th>y</th>\n","      <th>y_prev</th>\n","      <th>y_diff</th>\n","      <th>y_diff_std</th>\n","      <th>y_diff_norm</th>\n","      <th>IPOyear</th>\n","      <th>Sector</th>\n","      <th>Industry</th>\n","      <th>List1</th>\n","      <th>List2</th>\n","      <th>Year</th>\n","      <th>Month</th>\n","      <th>Day</th>\n","      <th>WeekOfYear</th>\n","      <th>List</th>\n","      <th>lag_1</th>\n","      <th>lag_2</th>\n","      <th>lag_3</th>\n","      <th>lag_4</th>\n","      <th>rmean_1_52</th>\n","      <th>rstd_1_52</th>\n","      <th>Skew_13</th>\n","      <th>Skew_26</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2011-11-13</td>\n","      <td>VGSH</td>\n","      <td>4.042036</td>\n","      <td>4.042036</td>\n","      <td>0.0</td>\n","      <td>0.017516</td>\n","      <td>0.0</td>\n","      <td>1970.0</td>\n","      <td>0.007648</td>\n","      <td>0.007648</td>\n","      <td>0.003676</td>\n","      <td>0.003665</td>\n","      <td>2011</td>\n","      <td>11</td>\n","      <td>13</td>\n","      <td>45</td>\n","      <td>NASDAQ</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.005307</td>\n","      <td>0.037524</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2011-11-13</td>\n","      <td>JEF</td>\n","      <td>2.925793</td>\n","      <td>2.925793</td>\n","      <td>0.0</td>\n","      <td>0.141216</td>\n","      <td>0.0</td>\n","      <td>1970.0</td>\n","      <td>0.006327</td>\n","      <td>0.003095</td>\n","      <td>0.005265</td>\n","      <td>0.005255</td>\n","      <td>2011</td>\n","      <td>11</td>\n","      <td>13</td>\n","      <td>45</td>\n","      <td>NYSE</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.005307</td>\n","      <td>0.037524</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2011-11-13</td>\n","      <td>IVZ</td>\n","      <td>2.692657</td>\n","      <td>2.692657</td>\n","      <td>0.0</td>\n","      <td>0.215237</td>\n","      <td>0.0</td>\n","      <td>1970.0</td>\n","      <td>0.006327</td>\n","      <td>0.005636</td>\n","      <td>0.005265</td>\n","      <td>0.005255</td>\n","      <td>2011</td>\n","      <td>11</td>\n","      <td>13</td>\n","      <td>45</td>\n","      <td>NYSE</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.005307</td>\n","      <td>0.037524</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2011-11-13</td>\n","      <td>KTCC</td>\n","      <td>1.752672</td>\n","      <td>1.752672</td>\n","      <td>0.0</td>\n","      <td>0.207799</td>\n","      <td>0.0</td>\n","      <td>1983.0</td>\n","      <td>0.003404</td>\n","      <td>0.003106</td>\n","      <td>0.003676</td>\n","      <td>0.003665</td>\n","      <td>2011</td>\n","      <td>11</td>\n","      <td>13</td>\n","      <td>45</td>\n","      <td>NASDAQ</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.005307</td>\n","      <td>0.037524</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2011-11-13</td>\n","      <td>FBZ</td>\n","      <td>2.695899</td>\n","      <td>2.695899</td>\n","      <td>0.0</td>\n","      <td>0.224060</td>\n","      <td>0.0</td>\n","      <td>1970.0</td>\n","      <td>0.007648</td>\n","      <td>0.007648</td>\n","      <td>0.003676</td>\n","      <td>0.003665</td>\n","      <td>2011</td>\n","      <td>11</td>\n","      <td>13</td>\n","      <td>45</td>\n","      <td>NASDAQ</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.005307</td>\n","      <td>0.037524</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1376755</th>\n","      <td>2019-11-24</td>\n","      <td>TYG</td>\n","      <td>NaN</td>\n","      <td>2.884177</td>\n","      <td>NaN</td>\n","      <td>0.141783</td>\n","      <td>NaN</td>\n","      <td>2004.0</td>\n","      <td>0.007648</td>\n","      <td>0.007648</td>\n","      <td>0.005265</td>\n","      <td>0.005255</td>\n","      <td>2019</td>\n","      <td>11</td>\n","      <td>24</td>\n","      <td>47</td>\n","      <td>NYSE</td>\n","      <td>-0.087223</td>\n","      <td>-0.051072</td>\n","      <td>-0.207735</td>\n","      <td>0.031837</td>\n","      <td>-0.018841</td>\n","      <td>0.221444</td>\n","      <td>-0.105451</td>\n","      <td>0.182783</td>\n","    </tr>\n","    <tr>\n","      <th>1376756</th>\n","      <td>2019-11-24</td>\n","      <td>VIRC</td>\n","      <td>NaN</td>\n","      <td>1.543298</td>\n","      <td>NaN</td>\n","      <td>0.264580</td>\n","      <td>NaN</td>\n","      <td>1970.0</td>\n","      <td>0.005102</td>\n","      <td>0.003960</td>\n","      <td>0.003676</td>\n","      <td>0.003665</td>\n","      <td>2019</td>\n","      <td>11</td>\n","      <td>24</td>\n","      <td>47</td>\n","      <td>NASDAQ</td>\n","      <td>-0.196693</td>\n","      <td>-0.120716</td>\n","      <td>0.059876</td>\n","      <td>0.037910</td>\n","      <td>-0.010175</td>\n","      <td>0.153233</td>\n","      <td>-0.136166</td>\n","      <td>-0.018302</td>\n","    </tr>\n","    <tr>\n","      <th>1376757</th>\n","      <td>2019-11-24</td>\n","      <td>BIS</td>\n","      <td>NaN</td>\n","      <td>2.754241</td>\n","      <td>NaN</td>\n","      <td>1.087817</td>\n","      <td>NaN</td>\n","      <td>1970.0</td>\n","      <td>0.007648</td>\n","      <td>0.007648</td>\n","      <td>0.003676</td>\n","      <td>0.003665</td>\n","      <td>2019</td>\n","      <td>11</td>\n","      <td>24</td>\n","      <td>47</td>\n","      <td>NASDAQ</td>\n","      <td>-0.059202</td>\n","      <td>-0.017845</td>\n","      <td>-0.009060</td>\n","      <td>-0.071397</td>\n","      <td>-0.005512</td>\n","      <td>0.064397</td>\n","      <td>0.198872</td>\n","      <td>0.211639</td>\n","    </tr>\n","    <tr>\n","      <th>1376758</th>\n","      <td>2019-11-24</td>\n","      <td>WOOD</td>\n","      <td>NaN</td>\n","      <td>4.184112</td>\n","      <td>NaN</td>\n","      <td>0.225542</td>\n","      <td>NaN</td>\n","      <td>1970.0</td>\n","      <td>0.007648</td>\n","      <td>0.007648</td>\n","      <td>0.003676</td>\n","      <td>0.003665</td>\n","      <td>2019</td>\n","      <td>11</td>\n","      <td>24</td>\n","      <td>47</td>\n","      <td>NASDAQ</td>\n","      <td>-0.047620</td>\n","      <td>0.020729</td>\n","      <td>0.060736</td>\n","      <td>0.044388</td>\n","      <td>0.004269</td>\n","      <td>0.127733</td>\n","      <td>0.718619</td>\n","      <td>0.066684</td>\n","    </tr>\n","    <tr>\n","      <th>1376759</th>\n","      <td>2019-11-24</td>\n","      <td>MASI</td>\n","      <td>NaN</td>\n","      <td>5.039223</td>\n","      <td>NaN</td>\n","      <td>0.682216</td>\n","      <td>NaN</td>\n","      <td>2007.0</td>\n","      <td>0.001624</td>\n","      <td>0.004483</td>\n","      <td>0.003676</td>\n","      <td>0.003665</td>\n","      <td>2019</td>\n","      <td>11</td>\n","      <td>24</td>\n","      <td>47</td>\n","      <td>NASDAQ</td>\n","      <td>0.034399</td>\n","      <td>0.067852</td>\n","      <td>-0.045713</td>\n","      <td>0.037691</td>\n","      <td>0.011138</td>\n","      <td>0.054559</td>\n","      <td>1.461108</td>\n","      <td>0.564073</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1376760 rows × 25 columns</p>\n","</div>"],"text/plain":["              Date    id         y    y_prev  y_diff  y_diff_std  y_diff_norm  \\\n","0       2011-11-13  VGSH  4.042036  4.042036     0.0    0.017516          0.0   \n","1       2011-11-13   JEF  2.925793  2.925793     0.0    0.141216          0.0   \n","2       2011-11-13   IVZ  2.692657  2.692657     0.0    0.215237          0.0   \n","3       2011-11-13  KTCC  1.752672  1.752672     0.0    0.207799          0.0   \n","4       2011-11-13   FBZ  2.695899  2.695899     0.0    0.224060          0.0   \n","...            ...   ...       ...       ...     ...         ...          ...   \n","1376755 2019-11-24   TYG       NaN  2.884177     NaN    0.141783          NaN   \n","1376756 2019-11-24  VIRC       NaN  1.543298     NaN    0.264580          NaN   \n","1376757 2019-11-24   BIS       NaN  2.754241     NaN    1.087817          NaN   \n","1376758 2019-11-24  WOOD       NaN  4.184112     NaN    0.225542          NaN   \n","1376759 2019-11-24  MASI       NaN  5.039223     NaN    0.682216          NaN   \n","\n","         IPOyear    Sector  Industry     List1     List2  Year  Month  Day  \\\n","0         1970.0  0.007648  0.007648  0.003676  0.003665  2011     11   13   \n","1         1970.0  0.006327  0.003095  0.005265  0.005255  2011     11   13   \n","2         1970.0  0.006327  0.005636  0.005265  0.005255  2011     11   13   \n","3         1983.0  0.003404  0.003106  0.003676  0.003665  2011     11   13   \n","4         1970.0  0.007648  0.007648  0.003676  0.003665  2011     11   13   \n","...          ...       ...       ...       ...       ...   ...    ...  ...   \n","1376755   2004.0  0.007648  0.007648  0.005265  0.005255  2019     11   24   \n","1376756   1970.0  0.005102  0.003960  0.003676  0.003665  2019     11   24   \n","1376757   1970.0  0.007648  0.007648  0.003676  0.003665  2019     11   24   \n","1376758   1970.0  0.007648  0.007648  0.003676  0.003665  2019     11   24   \n","1376759   2007.0  0.001624  0.004483  0.003676  0.003665  2019     11   24   \n","\n","         WeekOfYear    List     lag_1     lag_2     lag_3     lag_4  \\\n","0                45  NASDAQ  0.000000  0.000000  0.000000  0.000000   \n","1                45    NYSE  0.000000  0.000000  0.000000  0.000000   \n","2                45    NYSE  0.000000  0.000000  0.000000  0.000000   \n","3                45  NASDAQ  0.000000  0.000000  0.000000  0.000000   \n","4                45  NASDAQ  0.000000  0.000000  0.000000  0.000000   \n","...             ...     ...       ...       ...       ...       ...   \n","1376755          47    NYSE -0.087223 -0.051072 -0.207735  0.031837   \n","1376756          47  NASDAQ -0.196693 -0.120716  0.059876  0.037910   \n","1376757          47  NASDAQ -0.059202 -0.017845 -0.009060 -0.071397   \n","1376758          47  NASDAQ -0.047620  0.020729  0.060736  0.044388   \n","1376759          47  NASDAQ  0.034399  0.067852 -0.045713  0.037691   \n","\n","         rmean_1_52  rstd_1_52   Skew_13   Skew_26  \n","0          0.005307   0.037524  0.000000  0.000000  \n","1          0.005307   0.037524  0.000000  0.000000  \n","2          0.005307   0.037524  0.000000  0.000000  \n","3          0.005307   0.037524  0.000000  0.000000  \n","4          0.005307   0.037524  0.000000  0.000000  \n","...             ...        ...       ...       ...  \n","1376755   -0.018841   0.221444 -0.105451  0.182783  \n","1376756   -0.010175   0.153233 -0.136166 -0.018302  \n","1376757   -0.005512   0.064397  0.198872  0.211639  \n","1376758    0.004269   0.127733  0.718619  0.066684  \n","1376759    0.011138   0.054559  1.461108  0.564073  \n","\n","[1376760 rows x 25 columns]"]},"metadata":{},"execution_count":5}]},{"cell_type":"markdown","metadata":{"id":"gNE_MJpfTCpD"},"source":["## 学習、予測"]},{"cell_type":"code","metadata":{"id":"3qio_9OVUEzM"},"source":["def build_model(params):\n","  tf.random.set_seed(SEED)\n","\n","  dr = params['dropout_rate'] if 'dropout_rate' in params else 0\n","  kernel_initializer = tf.keras.initializers.GlorotUniform(seed=SEED) if 'kernel_initializer' not in params \\\n","    else tf.keras.initializers.HeUniform(seed=SEED) if params['kernel_initializer'] == 'he_uniform' \\\n","    else tf.keras.initializers.HeNormal(seed=SEED) if params['kernel_initializer'] == 'he_normal' \\\n","    else tf.keras.initializers.GlorotUniform(seed=SEED)\n","\n","  optimizer_func = tf.keras.optimizers.Adam if 'optimizer' not in params else tf.keras.optimizers.RMSprop if params['optimizer'] == 'RMSprop' \\\n","    else tf.keras.optimizers.Adam if params['optimizer'] == 'Adam' else tf.keras.optimizers.Adam\n","\n","  activation = params['activation'] if 'activation' in params else 'ReLU'\n","  use_batch_norm = params['use_batch_norm'] if 'use_batch_norm' in params else False\n","\n","  def activation_layer(activation):\n","    return layers.ReLU() if activation == 'ReLU' else layers.PReLU() if activation == 'PReLU' else layers.Activation(activations.swish) if activation == 'Swish' else layers.ReLU()\n","\n","  model = tf.keras.Sequential()\n","  for i, unit in enumerate(params['layers']):\n","    model.add(layers.Dense(unit, kernel_initializer=kernel_initializer))\n","    if use_batch_norm:\n","      model.add(layers.BatchNormalization())\n","    model.add(layers.Dropout(dr, seed=SEED))\n","    model.add(activation_layer(activation))\n","  model.add(layers.Dense(1, kernel_initializer=kernel_initializer))\n","\n","  if 'lr' in params:\n","    optimizer = optimizer_func(params['lr'])\n","  else:\n","    optimizer = optimizer_func()\n","\n","  if 'optimizer' in params and params['optimizer'] == 'AMSGrad':\n","    optimizer.amsgrad = True\n","\n","  model.compile(loss='mean_squared_error',\n","                optimizer=optimizer,\n","                metrics=['mse', 'msle'])\n","  \n","  return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2fjME7aLENOy"},"source":["def train_evaluate(price_df, submission_df):\n","  test_size = 0.01\n","\n","  # データの分離\n","  train_df = price_df.loc[price_df.Date < Config.submission_date].reset_index(drop=True)\n","  submit_df = price_df.loc[price_df.Date == Config.submission_date].reset_index(drop=True)\n","  original_train_df = train_df.copy()\n","\n","  if test_size == 0:\n","    pass\n","  else:\n","    unique_id = train_df.id.unique()\n","    train_id, test_id = train_test_split(unique_id, test_size=test_size, random_state=SEED)\n","    train_df = train_df.loc[train_df.id.isin(train_id), :]\n","\n","  useless_cols = [\n","    'y', 'y_prev', 'y_diff', 'y_diff_std', 'y_diff_norm', 'Date', 'id',\n","    'Market_y', 'Market_y_prev', 'Market_y_diff', 'Market_y_diff_std', 'Market_y_diff_norm', 'List'\n","  ]\n","  usable_cols = train_df.columns[~train_df.columns.isin(useless_cols)]\n","  target_col = 'y_diff_norm'\n","\n","  x_train = train_df[usable_cols]\n","  y_train = train_df[target_col]\n","  x_submit = submit_df[usable_cols]\n","\n","  # パラメーター\n","  params = defaultdict(None)\n","  params['NUM_ROUND'] = 30\n","  params['layers'] = (128, 128, 128, 128)\n","  params['kernel_initializer'] = 'he_uniform'\n","  params['use_batch_norm'] = True\n","  params['dropout_rate'] = 0.5\n","  params['activation'] = 'ReLU'\n","  params['BATCH_SIZE'] = 32\n","  steps_per_epoch = len(x_train) // params['BATCH_SIZE']\n","  params['lr'] = tfa.optimizers.CyclicalLearningRate(\n","      initial_learning_rate=0.001,\n","      maximal_learning_rate=0.001,\n","      scale_fn=lambda x: 1/(2.**(x-1)),\n","      step_size=2 * steps_per_epoch\n","  )\n","  params['optimizer'] = 'AMSGrad'\n","  es = tf.keras.callbacks.EarlyStopping(monitor='mse', patience=2, mode='min')\n","\n","  # 学習\n","  y_diff_std = train_df['y_diff_std']\n","  y_submit = []\n","\n","  unique_id = train_df.id.unique()\n","  kf = KFold(n_splits=5, shuffle=True, random_state=SEED)\n","  for fold, (tr_group_idx, va_group_idx) in enumerate(kf.split(unique_id)):\n","    print(f'fold: {fold+1} start.')\n","    \n","    tr_groups, va_groups = unique_id[tr_group_idx], unique_id[va_group_idx]\n","    tr_idx = train_df.id.isin(tr_groups)\n","    vl_idx = train_df.id.isin(va_groups)\n","\n","    x_tr_fold = x_train[tr_idx]\n","    y_tr_fold = y_train[tr_idx]\n","    x_vl_fold = x_train[vl_idx]\n","    y_vl_fold = y_train[vl_idx]\n","\n","    model = build_model(params)\n","    history = model.fit(\n","      x_tr_fold,\n","      y_tr_fold,\n","      epochs=params['NUM_ROUND'], \n","      validation_data=(x_vl_fold, y_vl_fold),\n","      shuffle=True,\n","      callbacks=[es],\n","      verbose=1,\n","      batch_size=params['BATCH_SIZE'],\n","    )\n","\n","    y_submit.append(model.predict(x_submit))\n","\n","  # submissionデータ作成\n","  submission_df['y'] = submit_df['y']\n","  submission_df['y_prev'] = submit_df['y_prev']\n","  submission_df['y_diff_std'] = submit_df['y_diff_std']\n","  submission_df['y_diff_norm'] = submit_df['y_diff_norm']\n","  submission_df['pred_y'] = np.mean(y_submit, axis=0).flatten() * submit_df['y_diff_std'].values + submit_df['y_prev'].values\n","  submission_df['exp_pred_y'] = np.expm1(submission_df['pred_y'])\n","  submission_df.loc[submission_df['exp_pred_y'] < 0, 'exp_pred_y'] = 0\n","  submission_df['pred_y_diff_norm'] = np.mean(y_submit, axis=0).flatten()\n","  submission_df['List'] = submit_df['List']\n","  submission_df['List1'] = submit_df['List1']\n","\n","  return model, submission_df\n","\n","\n","model, submission_df = train_evaluate(price_df3, submission_df)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_B17pnkMWBSr"},"source":["## submissionファイル作成"]},{"cell_type":"code","source":["submission_df2 = submission_df[['id', 'exp_pred_y']]\n","submission_df2.columns = ['id', 'y']"],"metadata":{"id":"Loe3pbFiL-Ds"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HCpSrGwjENLY"},"source":["submission_df2.to_csv(f'{Config.intermediate_dir_name}/submission_mlp_NYSE.csv', index=False)"],"execution_count":null,"outputs":[]}]}